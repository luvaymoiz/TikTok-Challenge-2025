{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffb3f7bc",
   "metadata": {},
   "source": [
    "# Fusing results from both Isolation Forest and Autoencoder #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b09e783",
   "metadata": {},
   "source": [
    "Importing libraries and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8769e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "AE_PATH  = \"AE_final_dataset_with_scores.parquet\"\n",
    "IF_PATH  = \"IF_final_dataset_with_scores.parquet\"\n",
    "BASE_IN  = \"final_dataset.parquet\"\n",
    "BASE_OUT_PARQUET = \"final_dataset_with_fusion.parquet\"\n",
    "BASE_OUT_CSV     = \"final_dataset_with_fusion.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9d01a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY_COL = None          # use this col to merge; else align by row order if 'None'\n",
    "AE_SCORE_COL = \"ae_reconstruction_error_zscore\" # score column name in AE file\n",
    "IF_SCORE_COL = \"anomaly_score\" # score column name in IF file\n",
    "\n",
    "NORMALIZE = True        # min-max per model before fusion\n",
    "FUSION    = \"mean\"      # fusion strategy: \"mean\" | \"max\" | \"rank_mean\"\n",
    "PERCENTILE = 95.0       # threshold = top 5% by default\n",
    "FIXED_THRESHOLD = None  # to override percentile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cffe1c9",
   "metadata": {},
   "source": [
    "minmax_0_1 function scales values to [0,1]. Handles NaNs and constant columns gracefully\n",
    "\n",
    "to_rank_0_1 function converts to percentile ranks [0,1]. Useful if score scales are incomparable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21ec72b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_0_1(s: pd.Series) -> pd.Series:\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    mn, mx = s.min(skipna=True), s.max(skipna=True)\n",
    "    if pd.isna(mn) or pd.isna(mx) or mn == mx:\n",
    "        return pd.Series(0.0, index=s.index)\n",
    "    return (s - mn) / (mx - mn)\n",
    "\n",
    "def to_rank_0_1(s: pd.Series) -> pd.Series:\n",
    "    return s.rank(method=\"average\", pct=True)  # uniform [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d385eea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "AE = pd.read_parquet(AE_PATH)\n",
    "IF = pd.read_parquet(IF_PATH)\n",
    "BASE = pd.read_parquet(BASE_IN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a261b0",
   "metadata": {},
   "source": [
    "Extracting columns and renaming for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e8f55c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_df = AE[[KEY_COL, AE_SCORE_COL]].copy() if KEY_COL else AE[[AE_SCORE_COL]].copy()\n",
    "if KEY_COL: ae_df = ae_df.rename(columns={AE_SCORE_COL: \"ae_score\", KEY_COL: KEY_COL})\n",
    "else:       ae_df = ae_df.rename(columns={AE_SCORE_COL: \"ae_score\"})\n",
    "\n",
    "if_df = IF[[KEY_COL, IF_SCORE_COL]].copy() if KEY_COL else IF[[IF_SCORE_COL]].copy()\n",
    "if KEY_COL: if_df = if_df.rename(columns={IF_SCORE_COL: \"if_score\", KEY_COL: KEY_COL})\n",
    "else:       if_df = if_df.rename(columns={IF_SCORE_COL: \"if_score\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085404e2",
   "metadata": {},
   "source": [
    "Aligning IF and AE results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "622be835",
   "metadata": {},
   "outputs": [],
   "source": [
    "if KEY_COL:\n",
    "    fused = pd.merge(if_df, ae_df, on=KEY_COL, how=\"inner\", validate=\"one_to_one\")\n",
    "else:\n",
    "    # row-order alignment\n",
    "    n = min(len(ae_df), len(if_df))\n",
    "    fused = pd.concat([if_df.iloc[:n].reset_index(drop=True),\n",
    "                       ae_df.iloc[:n].reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82585d48",
   "metadata": {},
   "source": [
    "if NORMALIZE is toggled to yes, then normalise score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9217470",
   "metadata": {},
   "outputs": [],
   "source": [
    "if NORMALIZE:\n",
    "    s_if = minmax_0_1(fused[\"if_score\"])\n",
    "    s_ae = minmax_0_1(fused[\"ae_score\"])\n",
    "else:\n",
    "    s_if = pd.to_numeric(fused[\"if_score\"], errors=\"coerce\")\n",
    "    s_ae = pd.to_numeric(fused[\"ae_score\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa303bd",
   "metadata": {},
   "source": [
    "Fuse scores based on FUSION mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08405711",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FUSION == \"mean\":\n",
    "    fusion = (s_if + s_ae) / 2.0\n",
    "elif FUSION == \"max\":\n",
    "    fusion = pd.concat([s_if, s_ae], axis=1).max(axis=1)\n",
    "elif FUSION == \"rank_mean\":\n",
    "    fusion = (to_rank_0_1(s_if) + to_rank_0_1(s_ae)) / 2.0\n",
    "else:\n",
    "    raise ValueError(f\"Unknown fusion method: {FUSION}\")\n",
    "\n",
    "fused[\"fusion_anomaly_score\"] = fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eb9357",
   "metadata": {},
   "source": [
    "Pitting against threshold to determine the anomaly flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1969fe49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion threshold: 0.478526\n",
      "Flagged anomalies: 1332/26622\n"
     ]
    }
   ],
   "source": [
    "if FIXED_THRESHOLD is not None:\n",
    "    th = float(FIXED_THRESHOLD)\n",
    "else:\n",
    "    th = float(np.percentile(fused[\"fusion_anomaly_score\"].dropna().values, PERCENTILE))\n",
    "\n",
    "fused[\"is_anomaly\"] = (fused[\"fusion_anomaly_score\"] >= th).astype(int)\n",
    "\n",
    "print(f\"Fusion threshold: {th:.6f}\")\n",
    "print(f\"Flagged anomalies: {int(fused['is_anomaly'].sum())}/{len(fused)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c740bd1",
   "metadata": {},
   "source": [
    "Merging back to base dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f874d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "if KEY_COL and KEY_COL in BASE.columns and KEY_COL in fused.columns:\n",
    "    out = pd.merge(\n",
    "        BASE,\n",
    "        fused[[KEY_COL, \"if_score\", \"ae_score\", \"fusion_anomaly_score\", \"is_anomaly\"]],\n",
    "        on=KEY_COL, how=\"left\", validate=\"one_to_one\"\n",
    "    )\n",
    "else:\n",
    "    m = min(len(BASE), len(fused))\n",
    "    out = BASE.iloc[:m].copy()\n",
    "    for c in [\"if_score\", \"ae_score\", \"fusion_anomaly_score\", \"is_anomaly\"]:\n",
    "        out[c] = fused.loc[:m-1, c].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca96b53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      "- Parquet: final_dataset_with_fusion.parquet\n",
      "- CSV    : final_dataset_with_fusion.csv\n"
     ]
    }
   ],
   "source": [
    "out.to_parquet(BASE_OUT_PARQUET, index=False)\n",
    "out.to_csv(BASE_OUT_CSV, index=False)\n",
    "print(\"Saved:\")\n",
    "print(f\"- Parquet: {BASE_OUT_PARQUET}\")\n",
    "print(f\"- CSV    : {BASE_OUT_CSV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca91c752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "26617    0\n",
      "26618    0\n",
      "26619    0\n",
      "26620    1\n",
      "26621    0\n",
      "Name: is_anomaly, Length: 26622, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(out[\"is_anomaly\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
